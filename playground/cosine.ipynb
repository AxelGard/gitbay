{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def load_data():\n",
    "    PATH = \"../data/\"\n",
    "    contents = []\n",
    "    files = [f\"{PATH}{f}\" for f in listdir(PATH) if isfile(join(PATH, f))]\n",
    "    for file_path in files: \n",
    "        with open(file_path, \"r\") as f:\n",
    "            contents.append(f.read())\n",
    "    return files, contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def load_stop_words(path:str=\"../stopwords.txt\"):\n",
    "   words = []\n",
    "   with open(path, \"r\") as f: \n",
    "      words = f.read().split(\"\\n\")\n",
    "   assert len(words) != 0, \"no stop words were found\"\n",
    "   return words\n",
    "\n",
    "def clean(content:list):\n",
    "    ascii_char = [chr(i) for i in range(0,255)]\n",
    "    numbers = \"0123456789\"\n",
    "    non_acc_char =  \"\\n,.()[]{}`/:-_*=\\\\<>|&%@?!\\\"\\'#\" + numbers\n",
    "    non_acc_tokens = [\"https\",\"www\", \"com\", \"org\", \"license\"]\n",
    "    stop_words = load_stop_words()\n",
    "    for i, _ in enumerate(content):\n",
    "        for c in non_acc_char:\n",
    "            content[i] = content[i].replace(c, \" \")\n",
    "        content[i] = content[i].split(\" \")\n",
    "        content[i] = list(filter(lambda c: c != \"\", content[i]))\n",
    "        content[i] = [t for t in content[i] if not t in non_acc_tokens ] \n",
    "        content[i] = [s.lower() for s in content[i] if all(c in ascii_char for c in s)]\n",
    "        content[i] = [t for t in content[i] if not t in stop_words] \n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        content[i] = [ps.stem(t) for t in content[i]] \n",
    "\n",
    "\n",
    "    return [\" \".join(con) for con in content]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files, contents = load_data()\n",
    "contents = clean(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "mat = vectorizer.fit_transform(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build app javascript\n",
      "[[0.0724035  0.02881532 0.10567176 0.00256731 0.         0.03792033\n",
      "  0.03832463 0.03578802 0.09258942 0.01062844]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/linux_README.txt',\n",
       " '../data/cpython_README.rst',\n",
       " '../data/svelte_README.md',\n",
       " '../data/rust_README.md',\n",
       " '../data/react_README.md']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \"build web apps with javascript\"\n",
    "\n",
    "query = clean([query])[0]\n",
    "print(query)\n",
    "q_vec = vectorizer.transform([query])\n",
    "simi = cosine_similarity(q_vec, mat)\n",
    "print(simi)\n",
    "idxs = simi.argsort()[0]\n",
    "simi_limit = 0.037\n",
    "[files[idx] for idx in idxs if simi[0][idx] > simi_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
